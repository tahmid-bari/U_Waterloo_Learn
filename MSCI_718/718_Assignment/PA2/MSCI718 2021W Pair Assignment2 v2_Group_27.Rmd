---
title: "Pair Assignment 2"
author: "MSCI 718"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#install.packages("csv")
#install.packages("xlsx")
#install.packages("pastecs")
#install.packages("rcompanion")
library(rlang)
library(dplyr)
library(ggplot2)
library(readxl)     # Read excel
library(readr)      # Read csv
library(tidyverse)
library(knitr)      # For knitting document and include_graphics function
library(gridExtra)  # For including grids of plots
library(pastecs)    # For skewness and kurtosis, command from the `pastecs` library, `stat.desc()`
library(rcompanion) # For Log, Square and cube root transformation
```

*Instructions: Working in groups of size 1 or 2, complete this assignment and submit online to the LEARN Dropbox as a ***_PDF (max 2 pages)_***. Also upload any source files, for example, any .R or .Rmd files that you used, and an appendix (PDF, Rmd, Word, or MD) describing the contributions of each group member. If you discussed problems with other students, please describe the nature of that discussion (e.g., on Team, in a study group). Remember, you can discuss approaches to problems with other groups, but ***_the work you submit must be your own._**

*In this assignment, you will perform exploratory data analysis and summarize a dataset. You may include any number of appendices showing your work.*

You are concerned about global health epidemics, and want to check which factors may be related to tuberculosis. Navigate to https://www.who.int/tb/country/data/download/en/ and review the various data sets; you will need to pick one pair of variables that you'd like to test for correlation. These variables may be from any datasets.

**For your one report**, include the following sections:

 1. Data: summarize the dataset(s), describe the number of observations, what variables there are, their levels of measurement/data type, and summary statistics for variables related to your analysis. Use plots as appropriate. Make sure to filter, tidy, and clean your data as discussed in class.
 2. Planning: identify the variables that you will analyze, check assumptions of the test(s) that you wish to carry out, and choose the appropriate correlation test. You may not be able to report all output, but do be explicit about what test(s) you pick and why, and whether you transform the data at all. 
 3. Analysis: Clearly identify the question and/or hypothesis you have before your analysis - this may be a hypothesis you have *a priori*, or one generated from a brief exploration of the data, but must be specified before you do your actual test. Use plots as appropriate.
 4. Conclusion: write up a conclusion for your analysis and what it might mean.


## Set working directory {.build}
```{r}
setwd("C:/Users/Tahmid Bari/Desktop/UWaterloo/Study/MSCI_718/718_Assignment/Assignment_2")
```
## Check working directory {.build}
```{r}
getwd()
```
## Read the data file {.build}
```{r}
tbData <- read_csv("TB_burden_countries_2021-02-11.csv")
file.exists("C:\\Users\\Tahmid Bari\\Desktop\\UWaterloo\\Study\\MSCI_718\\718_Assignment\\Assignment_2\\TB_burden_countries_2021-02-11.csv")
```

## Tidy {.build}
Now that we have our data, what are the variables? What are the observations? Is the data tidy?

```{r echo=FALSE}
tbData
```

## Tidy {.build}
Let's describe the dataset.

This is a dataset of `TB_burden_age_sex_2021-02-11(tbData)` TB burden with
There are thirteen variables:
Each variable has a column, and each observation on those variables has one row. So, the day is already tidy and no rearrangements need to be done.

```{r}
tbData_2 <- select(tbData, country, year, e_pop_num, e_inc_100k)
tbData_3 <- filter(tbData_2, year == "2019")
tbData_4 <- select(tbData_3, country, e_pop_num, e_inc_100k)
summary(tbData_4)
```

## Clean {.build}
The data is in the right format, but we want to make sure that each variable is well represented.
Let's start investigating them.

`e_pop_num` (Estimated total population number), e_inc_100k(Estimated incidence (all forms) per 100 000 population) are numerical values, currently stored as a double. We want this to be an integer value, so let's try re-loading the dataset explicitly parsing those values as an integer.

#Convert Data type
```{r}
tbData_4$e_pop_num=as.integer(tbData_3$e_pop_num)
tbData_4$e_inc_100k=as.integer(tbData_3$e_inc_100k)
```

## Clean {.build}

`col_integer()` will return `NA` if it fails to parse an integer, so let's make sure there are no missing values for e_pop_num:
`col_integer()` will return `NA` if it fails to parse an integer, so let's make sure there are no missing values for e_inc_100k:

```{r}
tbData_4 %>%
  summarize(missing_e_pop_num = sum(is.na(e_pop_num)))
```
```{r}
tbData_4 %>%
  summarize(missing_e_inc_100k = sum(is.na(e_inc_100k)))
```

## Omit the NAs in tbData_3 :: tbData_4 <- na.omit(tbData_3)

## Data Manipulation
## Input data {.build}

A first way to get information might be to look at the data structure:

```{r}
str(tbData_4)
tbData_4
```

## Input data {.build}
Or look at the data in summary:

```{r}
summary(tbData_4)
```

## Clean {.build}
`col_integer()` will return `NA` if it fails to parse an integer, so let's make sure there are no missing values for e_pop_num:
`col_integer()` will return `NA` if it fails to parse an integer, so let's make sure there are no missing values for e_inc_100k:

```{r}
tbData_4 %>%
  select(starts_with("e_pop_num")) %>% 
  summarise_all(~ sum(is.na(.))) # "~" defines a lambda function
```
```{r}
tbData_4 %>%
  select(starts_with("e_inc_100k")) %>% 
  summarise_all(~ sum(is.na(.))) # "~" defines a lambda function
```

#Basic Scatterplot
```{r}
plot(tbData_4$e_pop_num,tbData_4$e_inc_100k,xlab = 'Estimated Total Population Number',ylab = 'Estimated incidence (all forms) per 100 000 population', col="blue")
```

#Outliers of Estimated incidence (all forms) per 100 000 population
```{r}
ggplot(tbData_4, aes(y=e_pop_num)) + 
  geom_boxplot(outlier.colour = "red", outlier.shape = 8, outlier.size = 2)
```

#Arrange Estimated Total Population Number in desc order
```{r}
tbData_4 %>% 
  arrange(desc(e_pop_num))
```

## Outliers {.build}
```{r echo=FALSE}
tbData_4 %>% 
  ggplot(aes(e_pop_num, e_inc_100k)) + geom_boxplot()
```

## Outliers - Identifying and Removing it from the dataset
```{r}
tbData_4[which(tbData_4$e_pop_num %in% outliers),]
tbData_4 <- tbData_4[-which(tbData_4$e_pop_num %in% outliers),]
```

#Outliers of Boxplot of Estimated incidence (all forms) per 100 000 population
```{r}
boxplot(tbData_4$e_pop_num, col="green")
```

#Scatterplot with regression line
```{r}
ggplot(tbData_4, aes(x=e_pop_num, y=e_inc_100k)) + 
  geom_point() +
    geom_smooth(method=lm) +
      labs(title = "Scatterplot of TB (Dataset)",
        x = "e_pop_num (Estimated Total Population Number)",
        y = "e_inc_100k (Estimated incidence (all forms) per 100 000 population)")
```      

#histogram of Estimated Total Population Number
hist(x = tbData_4$e_pop_num,
     xlab = "e_pop_num",
     main = "Distribution of Estimated Total Population Number"
     )
     
#histogram of Estimated mortality of TB cases (all forms) per 100 000 population
hist(x = tbData_4$e_inc_100k,
     xlab = "e_inc_100k",
     main = "Distribution of Estimated incidence (all forms) per 100 000 population"
     )

#Boxplot with theme of the Distribution of TB (Dataset)
```{r}
ggplot(tbData_4, aes(x=e_pop_num, y=e_inc_100k, fill=e_pop_num)) +
  geom_boxplot() + ggtitle("Box Plot of Distribution of Estimated incidence (all forms) per 100 000 population") +
  scale_fill_brewer(palette = 'blue') + theme_light()
```

#Boxplot with colors
```{r}
ggplot(tbData_4, aes(x=e_pop_num, y=e_inc_100k, fill=e_pop_num)) +
  geom_boxplot() + ggtitle("Box Plot of Distribution of Estimated incidence (all forms) per 100 000 population")
```

#Horizontal boxplot
```{r}
ggplot(tbData_4, aes(x=e_pop_num, y=e_inc_100k, fill=e_pop_num)) +
  geom_boxplot() + coord_flip()
```
## Plot data {.build}
```{r echo=FALSE}
ggplot(tbData_4, aes(x=e_pop_num, y=e_inc_100k)) + geom_point() + geom_jitter()
```

## Check Assumptions

## Visual Inspection of Normality

We looked at two different graphs to see if our data was normal: histograms and Q-Q Plots

```{r}
tbData_4.nooutliers %>% 
  ggplot(aes(x=e_inc_100k)) + theme(legend.position = "none") +
    geom_histogram(aes(y=..density..)) + 
    stat_function(fun=dnorm, args=list(mean=mean(tbData_4$e_inc_100k, na.rm=TRUE), sd=sd(tbData_4$e_inc_100k, na.rm=TRUE)))
```

## Visual Inspection of Normality

We looked at two different graphs to see if our data was normal: histograms and Q-Q Plots
```{r}
tbData_4.nooutliers %>% 
  ggplot(aes(sample=e_inc_100k)) + stat_qq() + geom_qq_line(aes(color="red")) + theme(legend.position = "none")
```

## Quantitative Normality Tests {.build}
One approach might be to test for signifiers of non-normality.
For example, skewness and kurtosis.
To do this, we'll use a very handy command from the `pastecs` library, `stat.desc()`

```{r}
library(pastecs)
```

## Skewness and kurtosis {.build}

```{r echo=FALSE}
stat.desc(tbData_4.nooutliers$e_inc_100k, basic=FALSE, norm=TRUE)
```

## Skewness and kurtosis {.build}
We can use the `skew.2SE` and `kurt.2SE` values, which are normalized by dividing the skewness and kurtosis by 2 standard errors
This is very close to the value of 1.96, which is the 97.5\% quantile of the normal distribution (we look at two tails, so together 95\% of values are between -1.96 and 1.96 standard error in the sample distribution)

```{r}
qnorm(0.05/2)
```

## Skewness and kurtosis {.build}
We can use this as an approximation: if the absolute value of each `skew.2SE` or `kurt.2SE` is greater 1, then we can conclude with $\sim 95\%$ confidence that the skewness or kurtosis is not equal to zero, and thus that the distribution is not normal.
For these values, you can use approximate thresholds of 1 for $p < 0.05$, 1.29 for $p < 0.01$, and 1.65 for $p < 0.001$. 
More generally and precisely, you can use a threshold of `abs(qnorm(p/2))/2` for any p value you want.

## Skewness and kurtosis {.build}

So, what do we conclude from `e_inc_100k`?

```{r}
stat.desc(tbData_4.nooutliers$e_inc_100k, basic=FALSE, norm=TRUE)["skew.2SE"]
stat.desc(tbData_4.nooutliers$e_inc_100k, basic=FALSE, norm=TRUE)["kurt.2SE"]
```
Because `r stat.desc(tbData_4.nooutliers$e_inc_100k, basic=FALSE, norm=TRUE)["skew.2SE"]` is not between -1 and 1 at 5.735362, we conclude that the skewness for `e_inc_100k` is different from 0 (at the 95\% level of confidence) with positively skewed distribution.

Because `r stat.desc(dlf.nooutliers$day1, basic=FALSE, norm=TRUE)["kurt.2SE"]` is greater than 1 at 4.753397, we do conclude that the kurtosis for `e_inc_100k` is different from 0 (at the 95\% level of confidence) with positive kurtosis.

With larger samples, the standard errors are small, inflating these values. With a large sample (200+), it's more important to look at the shape of the distribution - this is why we started with Q-Q plots.


## Normal Q-Q Plot {.build}
qqnorm(tbData_4$e_inc_100k, pch = 1, frame = FALSE)
qqline(tbData_4$e_inc_100k, col = "steelblue", lwd = 2)

## Q-Q Plot
```{r}
library("car")
qqPlot(tbData_4$e_inc_100k)
```

## Shapiro-Wilk normality test
```{r}
tbData_4.nooutliers %>% 
  ggplot(aes(x=e_inc_100k)) + theme(legend.position = "none") +
    geom_histogram(aes(y=..density..)) + 
    stat_function(fun=dnorm, args=list(mean=mean(tbData_4$e_inc_100k, na.rm=TRUE), sd=sd(tbData_4$e_inc_100k, na.rm=TRUE)))
```

This data is not normal, and positively skewed. So, we need to the transformation.

## Log transformation
```{r}
T_log = log(tbData_4$e_inc_100k)
library(rcompanion) # For Log, Square and cube root transformation
plotNormalHistogram(T_log)
```

## Log transformation {.build}
```{r}
e_inc_100k <- data.frame(rlnorm(1000))
names(e_inc_100k) <- "e_inc_100k"
ggplot(e_inc_100k, aes(e_inc_100k)) + geom_histogram()+ scale_x_log10() + scale_y_log10()
```

## Square root transformation
```{r}
T_sqrt = sqrt(tbData_4$e_inc_100k) 
library(rcompanion) # For Log, Square and cube root transformation
plotNormalHistogram(T_sqrt)
```

## Cube root transformation
```{r}
T_cub = sign(tbData_4$e_inc_100k) * abs(tbData_4$e_inc_100k)^(1/3)
library(rcompanion) # For Log, Square and cube root transformation
plotNormalHistogram(T_sqrt)
```